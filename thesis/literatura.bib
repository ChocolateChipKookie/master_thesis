@article{fatima2021image,
  author        = {Fatima, Aroosh and Hussain, Wajahat and Rasool, Shahzad},
  title         = {Grey is the new RGB: How good is GAN-based image colorization for image compression?},
  year          = {2021},
  journal       = {Multimedia Tools and Applications}
}

@article{reinhard2001colorization,
  author        = {Reinhard, E. and Adhikhmin, M. and Gooch, B. and Shirley, P.},
  journal       = {IEEE Computer Graphics and Applications}, 
  title         = {Color transfer between images}, 
  year          = {2001},
  volume        = {21},
  number        = {5},
  pages         = {34-41},
  doi           = {10.1109/38.946629}
}

@article{levin2004colorization,
  author        = {Levin, Anat and Lischinski, Dani and Weiss, Yair},
  year          = {2004},
  month         = {06},
  pages         = {},
  title         = {Colorization using Optimization},
  volume        = {23},
  journal       = {ACM Transactions on Graphics},
  doi           = {10.1145/1015706.1015780}
}

@article{iizuka2016colorization,
  author        = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
  title         = {{Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification}},
  journal       = {ACM Transactions on Graphics (Proc. of SIGGRAPH 2016)},
  year          = {2016},
  volume        = {35},
  number        = {4},
  pages         = {110:1--110:11},
}

@article{fukushima1980neocognitron,
  author        = {Kunihiko Fukushima},
  title         = {{Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position}},
  journal       = {Biological Cybernetics},
  year          = {1980},
  volume        = {36},
  number        = {4},
  pages         = {193:1--202:9},
}

@article{ronneberger2015unet,
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal       = {CoRR},
  volume        = {abs/1505.04597},
  year          = {2015},
  url           = {http://arxiv.org/abs/1505.04597},
  archivePrefix = {arXiv},
  eprint        = {1505.04597},
  timestamp     = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl        =  {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{fei2004caltech,
  author        = {L. Fei-Fei, R. Fergus and P. Perona},
  title         = {{Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories}},
  journal       = {IEEE. CVPR 2004},
  publisher     = {IEEE},
  year          = {2004},
}

@article{zhou2017places,
  title         = {Places: A 10 million Image Database for Scene Recognition},
  author        = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year          = {2017},
  publisher     = {IEEE}
}

@article{krizhevskycifar,
  title         = {CIFAR-100 (Canadian Institute for Advanced Research)},
  journal       = {},
  author        = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
  year          = {},
  url           = {http://www.cs.toronto.edu/~kriz/cifar.html},
  abstract      = {This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which it belongs).
    Here is the list of classes in the CIFAR-100:

    Superclass	Classes
    aquatic mammals	beaver, dolphin, otter, seal, whale
    fish	aquarium fish, flatfish, ray, shark, trout
    flowers	orchids, poppies, roses, sunflowers, tulips
    food containers	bottles, bowls, cans, cups, plates
    fruit and vegetables	apples, mushrooms, oranges, pears, sweet peppers
    household electrical devices	clock, computer keyboard, lamp, telephone, television
    household furniture	bed, chair, couch, table, wardrobe
    insects	bee, beetle, butterfly, caterpillar, cockroach
    large carnivores	bear, leopard, lion, tiger, wolf
    large man-made outdoor things	bridge, castle, house, road, skyscraper
    large natural outdoor scenes	cloud, forest, mountain, plain, sea
    large omnivores and herbivores	camel, cattle, chimpanzee, elephant, kangaroo
    medium-sized mammals	fox, porcupine, possum, raccoon, skunk
    non-insect invertebrates	crab, lobster, snail, spider, worm
    people	baby, boy, girl, man, woman
    reptiles	crocodile, dinosaur, lizard, snake, turtle
    small mammals	hamster, mouse, rabbit, shrew, squirrel
    trees	maple, oak, palm, pine, willow
    vehicles 1	bicycle, bus, motorcycle, pickup truck, train
    vehicles 2	lawn-mower, rocket, streetcar, tank, tractor

    Yes, I know mushrooms aren't really fruit or vegetables and bears aren't really carnivores. },
  keywords      = {Dataset},
  terms         = {}
}

@article{zhang2017ideep,
  author        = {Richard Zhang and Jun{-}Yan Zhu and Phillip Isola and Xinyang Geng and Angela S. Lin and Tianhe Yu and Alexei A. Efros},
  title         = {Real-Time User-Guided Image Colorization with Learned Deep Priors},
  journal       = {CoRR},
  volume        = {abs/1705.02999},
  year          = {2017},
  url           = {http://arxiv.org/abs/1705.02999},
  archivePrefix = {arXiv},
  eprint        = {1705.02999},
  timestamp     = {Wed, 14 Aug 2019 08:23:33 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/ZhangZIGLYE17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{ioffe2015batchnorm,
  author        = {Sergey Ioffe and Christian Szegedy},
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  journal       = {CoRR},
  volume        = {abs/1502.03167},
  year          = {2015},
  url           = {http://arxiv.org/abs/1502.03167},
  archivePrefix = {arXiv},
  eprint        = {1502.03167},
  timestamp     = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/IoffeS15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{abien2018relu,
  author        = {Abien Fred Agarap},
  title         = {Deep Learning using Rectified Linear Units (ReLU)},
  journal       = {CoRR},
  volume        = {abs/1803.08375},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.08375},
  archivePrefix = {arXiv},
  eprint        = {1803.08375},
  timestamp     = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-08375.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{tantithamthavorn2020rebalancing,
  author        = {Tantithamthavorn, Chakkrit and Hassan, Ahmed E. and Matsumoto, Kenichi},
  journal       = {IEEE Transactions on Software Engineering}, 
  title         = {The Impact of Class Rebalancing Techniques on the Performance and Interpretation of Defect Prediction Models}, 
  year          = {2020},
  volume        = {46},
  number        = {11},
  pages         = {1200-1219},
  doi           = {10.1109/TSE.2018.2876537}
}

@article{isola2017pix2pix,
  title         = {Image-to-Image Translation with Conditional Adversarial Networks},
  author        = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal       = {CVPR},
  year          = {2017}
}

@article{nazeri2018gan,
  author        = {Kamyar Nazeri and Eric Ng},
  title         = {Image Colorization with Generative Adversarial Networks},
  journal       = {CoRR},
  volume        = {abs/1803.05400},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.05400},
  archivePrefix = {arXiv},
  eprint        = {1803.05400},
  timestamp     = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-05400.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{mirza2014cgan,
  author        = {Mehdi Mirza and Simon Osindero},
  title         = {Conditional Generative Adversarial Nets},
  journal       = {CoRR},
  volume        = {abs/1411.1784},
  year          = {2014},
  url           = {http://arxiv.org/abs/1411.1784},
  archivePrefix = {arXiv},
  eprint        = {1411.1784},
  timestamp     = {Mon, 13 Aug 2018 16:48:15 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/MirzaO14.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{lecun2010mnist,
  title         = {MNIST handwritten digit database},
  added-at      = {2010-06-28T21:16:30.000+0200},
  author        = {LeCun, Yann and Cortes, Corinna},
  biburl        = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups        = {public},
  howpublished  = {http://yann.lecun.com/exdb/mnist/}
},

@article{salimans2016improved_gans,
  author        = {Tim Salimans and Ian J. Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},
  title         = {Improved Techniques for Training GANs},
  journal       = {CoRR},
  volume        = {abs/1606.03498},
  year          = {2016},
  url           = {http://arxiv.org/abs/1606.03498},
  archivePrefix = {arXiv},
  eprint        = {1606.03498},
  timestamp     = {Sun, 16 Sep 2018 14:17:04 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SalimansGZCRC16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@book{henisch1996photograph,
  author        = {Henisch, Heinz K and Henisch, Bridget Ann},
  title         = {{The painted photograph, 1839-1914 : origins, techniques, aspirations}},
  publisher     = {Pennsylvania State University Press},
  year          = {1996}
}

@inproceedings {luan2007colorization,
  booktitle     = {Rendering Techniques},
  editor        = {Jan Kautz and Sumanta Pattanaik},
  title         = {{Natural Image Colorization}},
  author        = {Luan, Qing and Wen, Fang and Cohen-Or, Daniel and Liang, Lin and Xu, Ying-Qing and Shum, Heung-Yeung},
  year          = {2007},
  publisher     = {The Eurographics Association},
  ISSN          = {1727-3463},
  ISBN          = {978-3-905673-52-4},
  DOI           = {10.2312/EGWR/EGSR07/309-320}
}

@inproceedings{charpiat2008colorization,
  author        = {Charpiat, Guillaume and Hofmann, Matthias and Sch{\"o}lkopf, Bernhard},
  editor        = {Forsyth, David and Torr, Philip and Zisserman, Andrew},
  title         = {Automatic Image Colorization Via Multimodal Predictions},
  booktitle     = {Computer Vision -- ECCV 2008},
  year          = {2008},
  publisher     = {Springer Berlin Heidelberg},
  address       = {Berlin, Heidelberg},
  pages         = {126--139},
  abstract      = {We aim to color greyscale images automatically, without any manual intervention. The color proposition could then be interactively corrected by user-provided color landmarks if necessary. Automatic colorization is nontrivial since there is usually no one-to-one correspondence between color and local texture. The contribution of our framework is that we deal directly with multimodality and estimate, for each pixel of the image to be colored, the probability distribution of all possible colors, instead of choosing the most probable color at the local level. We also predict the expected variation of color at each pixel, thus defining a non-uniform spatial coherency criterion. We then use graph cuts to maximize the probability of the whole colored image at the global level. We work in the L-a-b color space in order to approximate the human perception of distances between colors, and we use machine learning tools to extract as much information as possible from a dataset of colored examples. The resulting algorithm is fast, designed to be more robust to texture noise, and is above all able to deal with ambiguity, in contrary to previous approaches.},
  isbn          = {978-3-540-88690-7}
}

@inproceedings{cheng2015colorization,
  author        = {Cheng, Zezhou and Yang, Qingxiong and Sheng, Bin},
  title         = {Deep Colorization},
  booktitle     = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month         = {December},
  year          = {2015}
}

@inproceedings{deng2009imagenet,
  author        = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  title         = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle     = {CVPR09},
  year          = {2009},
  bibsource     = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@inproceedings{zhang2016colorful,
  author        = {Zhang, Richard and Isola, Phillip and Efros, Alexei A.},
  editor        = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  title         = {Colorful Image Colorization},
  booktitle     = {Computer Vision -- ECCV 2016},
  year          = {2016},
  publisher     = {Springer International Publishing},
  address       = {Cham},
  pages         = {649--666},
  abstract      = {Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a ``colorization Turing test,'' asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32 {\%} of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.},
  isbn          = {978-3-319-46487-9},
}

@inproceedings{simonyan2015vgg,
  author        = {Karen Simonyan and Andrew Zisserman},
  editor        = {Yoshua Bengio and Yann LeCun},
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle     = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year          = {2015},
  url           = {http://arxiv.org/abs/1409.1556},
  timestamp     = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{yu2016atrous,
  author        = {Fisher Yu and Vladlen Koltun},
  title         = {Multi-Scale Context Aggregation by Dilated Convolutions},
  booktitle     = {International Conference on Learning Representations (ICLR)},
  year          = {2016},
  month         = {may}
}

@inproceedings{diederik2015adam,
  author        = {Diederik P. Kingma and Jimmy Ba},
  editor        = {Yoshua Bengio and Yann LeCun},
  title         = {Adam: {A} Method for Stochastic Optimization},
  booktitle     = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year          = {2015},
  url           = {http://arxiv.org/abs/1412.6980},
  timestamp     = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}


@manual{icc2004cielab,
  organization  = {International Color Consortium"},
  title         = {Image technology colour management — Architecture, profile format, and data structure},
  number        = {ICC.1:2004-10},
  year          = {2004},
  note          = {Profile version 4.2.0.0},
  url           = {https://www.color.org/icc1v42.pdf}
}

@misc{pan2019video,
  title         = {Video Compression Coding via Colorization: A Generative Adversarial Network (GAN)-Based Approach}, 
  author        = {Zhaoqing Pan and Feng Yuan and Jianjun Lei and Sam Kwong},
  year          = {2019},
  eprint        = {1912.10653},
  archivePrefix = {arXiv},
  primaryClass  = {eess.IV}
}

@misc{pang2021imagetoimage,
  title         = {Image-to-Image Translation: Methods and Applications}, 
  author        = {Yingxue Pang and Jianxin Lin and Tao Qin and Zhibo Chen},
  year          = {2021},
  eprint        = {2101.08629},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV}
}

@misc{goodfellow2014generative,
  title         = {Generative Adversarial Networks}, 
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year          = {2014},
  eprint        = {1406.2661},
  archivePrefix = {arXiv},
  primaryClass  = {stat.ML}
}

@misc{goodfellow2017nips,
  title         = {NIPS 2016 Tutorial: Generative Adversarial Networks}, 
  author        = {Ian Goodfellow},
  year          = {2017},
  eprint        = {1701.00160},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG}
}