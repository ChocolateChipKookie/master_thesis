\relax 
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\citation{henisch1996photograph}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:introduction}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Hand-colored photograph by Stillfried \& Andersen (made the period between 1862 and 1885)\relax }}{1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:hand_colored}{{1.1}{1}}
\newlabel{fig:stone_house:original}{{1.2a}{ii}}
\newlabel{sub@fig:stone_house:original}{{a}{ii}}
\newlabel{fig:stone_house:grayscale}{{1.2b}{ii}}
\newlabel{sub@fig:stone_house:grayscale}{{b}{ii}}
\newlabel{fig:stone_house:colorized}{{1.2c}{ii}}
\newlabel{sub@fig:stone_house:colorized}{{c}{ii}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Colorization example on an image of a stone house\relax }}{ii}\protected@file@percent }
\newlabel{fig:stone_house}{{1.2}{ii}}
\citation{pang2021imagetoimage}
\citation{icc2004cielab}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Base}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:base}{{2}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Colored image of Alim Khan taken by Sergey Prokudin-Gorsky in 1911 using the three-image color photography method on the left, and the green, red, and blue (top to bottom) filter negatives (shown as positives) on the right.\relax }}{1}\protected@file@percent }
\newlabel{fig:alim_khan}{{2.1}{1}}
\newlabel{eq:colorization}{{2.1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Color space}{2}\protected@file@percent }
\newlabel{sec:colorspace}{{2.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Slices of the CIELAB color space at different luminance levels, with only the RGB gamut rendered\relax }}{2}\protected@file@percent }
\newlabel{fig:rgb_in_lab}{{2.2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Image with seperated channels of the CIELAB color space\relax }}{2}\protected@file@percent }
\newlabel{fig:lab_channels}{{2.3}{2}}
\citation{levin2004colorization}
\citation{luan2007colorization}
\citation{charpiat2008colorization}
\citation{reinhard2001colorization}
\citation{cheng2015colorization}
\citation{iizuka2016colorization}
\newlabel{eq:colorization_2}{{2.2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Task definition}{3}\protected@file@percent }
\newlabel{sec:task}{{2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Multimodality}{3}\protected@file@percent }
\newlabel{sec:multimodality}{{2.2.1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Image of three scooters, colorizer input, and possible colorization\relax }}{4}\protected@file@percent }
\newlabel{fig:multimodality_scooters}{{2.4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Image of sea taken during a sunset, colorizer input, and possible colorization\relax }}{4}\protected@file@percent }
\newlabel{fig:multimodality_sunset}{{2.5}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Artificial neural networks}{4}\protected@file@percent }
\citation{fukushima1980neocognitron}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Comparison of biological and artificial neuron (stronger colors indicate higher weights)\relax }}{5}\protected@file@percent }
\newlabel{fig:neuron}{{2.6}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Convolutional neural networks}{5}\protected@file@percent }
\newlabel{sec:cnn}{{2.3.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}U-net}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Example of a U-Net with four downsampling and four upsampling blocks where the skip-connection is accomplished by concatinating outputs of the encoder to the upsampled features of the decoder\relax }}{6}\protected@file@percent }
\newlabel{fig:unet}{{2.7}{6}}
\citation{deng2009imagenet}
\citation{fei2004caltech}
\citation{zhou2017places}
\citation{krizhevskycifar}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Dataset}{vii}\protected@file@percent }
\newlabel{sec:dataset}{{2.4}{vii}}
\citation{zhang2016colorful}
\citation{simonyan2015vgg}
\citation{abien2018relu}
\citation{ioffe2015batchnorm}
\citation{yu2016atrous}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Models}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Colorful Image Colorization}{1}\protected@file@percent }
\newlabel{sec:colorful}{{3.1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Architecture}{1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Quantized \textbf  {a*b*} bins for different \textbf  {L*} values\relax }}{1}\protected@file@percent }
\newlabel{fig:lab_bins}{{3.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The architecture of the \textit  {Colorful Image Colorization} model. The eight convolutional blocks and the layer mapping the output to the probability distribution over the $Q$-bins are colored in yellow, and probability to \textbf  {a*b*} mapping in black\relax }}{2}\protected@file@percent }
\newlabel{fig:architecture_colorful}{{3.2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Annealed mean}{2}\protected@file@percent }
\newlabel{eq:annealed_mean}{{3.1}{2}}
\newlabel{eq:weighed sum}{{3.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Colorization of an image using different values of $T$\relax }}{3}\protected@file@percent }
\newlabel{fig:temperature}{{3.3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Original image on the left, and the same image where the resolution of the \textbf  {a*} and \textbf  {b*} channels was reduced by a factor of four on the right\relax }}{3}\protected@file@percent }
\newlabel{fig:color4}{{3.4}{3}}
\citation{diederik2015adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Training}{4}\protected@file@percent }
\newlabel{sec:colorful_training}{{3.1.3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces  The image is first resized to a size where the shorter of the two sides is $256$ pixels in length, afterwards a $256\times 256$ square is randomly cropped out of the resized image\relax }}{4}\protected@file@percent }
\newlabel{fig:crop}{{3.5}{4}}
\citation{zhang2016colorful}
\citation{zhang2016colorful}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Training step for the \textit  {Colorful Image Colorization} model\relax }}{5}\protected@file@percent }
\newlabel{alg:colorful}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Graph borrowed from the original paper \citep  {zhang2016colorful}, showing the overall distribution of color channel values in the ImageNet dataset, using a logarithmic scale (red indicates high, and blue low occurance)\relax }}{5}\protected@file@percent }
\newlabel{fig:distribution}{{3.6}{5}}
\citation{tantithamthavorn2020rebalancing}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Results}{6}\protected@file@percent }
\citation{goodfellow2014generative}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Generative Adversarial Networks for Colorization}{7}\protected@file@percent }
\newlabel{sec:gan}{{3.2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Architecture}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generative adversarial networks}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Analogy for the way GANs work\relax }}{7}\protected@file@percent }
\newlabel{fig:museum}{{3.7}{7}}
\citation{mirza2014cgan}
\citation{lecun2010mnist}
\citation{goodfellow2014generative}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces A successful result of a GAN trained on the MNIST dataset on the left, and an unsuccessful attempt that ended up in mode collapse on the right\relax }}{8}\protected@file@percent }
\newlabel{fig:gan_mnist}{{3.8}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Conditional GAN}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Generating fake hand-written digits based on the MNIST dataset using the cGAN framework. Digits in the same row are generated using the same latent vector (seed), and demonstrate similar characteristics\relax }}{9}\protected@file@percent }
\newlabel{fig:cgan_mnist}{{3.9}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Generator}{9}\protected@file@percent }
\citation{isola2017pix2pix}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The U-Net architecture of the model used for the generator, the short connection is done by concatenating the features from the encoder to the de-convoluted features of the previous layer in the decoder.\relax }}{10}\protected@file@percent }
\newlabel{fig:architecture_gan}{{3.10}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Discriminator}{10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces The patch-GAN discriminator architecture\relax }}{10}\protected@file@percent }
\newlabel{fig:architecture_gan_discriminator}{{3.11}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces The patch-GAN discriminator architecture\relax }}{11}\protected@file@percent }
\newlabel{fig:architecture_gan_full}{{3.12}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Training}{11}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Training step for the \textit  {Colorful Image Colorization} model\relax }}{11}\protected@file@percent }
\newlabel{alg:gan}{{2}{11}}
\citation{goodfellow2017nips}
\citation{salimans2016improved_gans}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Healthy back and forth between the generator and the discriminator. Discriminator error on real samples in red, and on fake samples in blue.\relax }}{12}\protected@file@percent }
\newlabel{fig:gan_plot}{{3.13}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Results}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Interactive Deep Colorization}{xiii}\protected@file@percent }
\newlabel{sec:ideep}{{3.3}{xiii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Architecture}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Transfer learning}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Global hints}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Training}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Results}{xiii}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related work}{i}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Related work}{i}\protected@file@percent }
\bibdata{literatura}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{i}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Possible improvements}{i}\protected@file@percent }
\bibcite{abien2018relu}{{1}{2018}{{Agarap}}{{}}}
\bibcite{charpiat2008colorization}{{2}{2008}{{Charpiat et~al.}}{{Charpiat, Hofmann, and Sch{\"o}lkopf}}}
\bibcite{cheng2015colorization}{{3}{2015}{{Cheng et~al.}}{{Cheng, Yang, and Sheng}}}
\bibcite{deng2009imagenet}{{4}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li, and Fei-Fei}}}
\bibcite{fukushima1980neocognitron}{{5}{1980}{{Fukushima}}{{}}}
\bibcite{goodfellow2017nips}{{6}{2017}{{Goodfellow}}{{}}}
\bibcite{goodfellow2014generative}{{7}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{henisch1996photograph}{{8}{1996}{{Henisch and Henisch}}{{}}}
\bibcite{iizuka2016colorization}{{9}{2016}{{Iizuka et~al.}}{{Iizuka, Simo-Serra, and Ishikawa}}}
\bibcite{icc2004cielab}{{10}{2004}{{Int}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{ii}\protected@file@percent }
\bibcite{ioffe2015batchnorm}{{11}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{isola2017pix2pix}{{12}{2017}{{Isola et~al.}}{{Isola, Zhu, Zhou, and Efros}}}
\bibcite{diederik2015adam}{{13}{2015}{{Kingma and Ba}}{{}}}
\bibcite{krizhevskycifar}{{14}{}{{Krizhevsky et~al.}}{{Krizhevsky, Nair, and Hinton}}}
\bibcite{fei2004caltech}{{15}{2004}{{L.~Fei-Fei and Perona}}{{}}}
\bibcite{lecun2010mnist}{{16}{}{{LeCun and Cortes}}{{}}}
\bibcite{levin2004colorization}{{17}{2004}{{Levin et~al.}}{{Levin, Lischinski, and Weiss}}}
\bibcite{luan2007colorization}{{18}{2007}{{Luan et~al.}}{{Luan, Wen, Cohen-Or, Liang, Xu, and Shum}}}
\bibcite{mirza2014cgan}{{19}{2014}{{Mirza and Osindero}}{{}}}
\bibcite{pang2021imagetoimage}{{20}{2021}{{Pang et~al.}}{{Pang, Lin, Qin, and Chen}}}
\bibcite{reinhard2001colorization}{{21}{2001}{{Reinhard et~al.}}{{Reinhard, Adhikhmin, Gooch, and Shirley}}}
\bibcite{salimans2016improved_gans}{{22}{2016}{{Salimans et~al.}}{{Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen}}}
\bibcite{simonyan2015vgg}{{23}{2015}{{Simonyan and Zisserman}}{{}}}
\bibcite{tantithamthavorn2020rebalancing}{{24}{2020}{{Tantithamthavorn et~al.}}{{Tantithamthavorn, Hassan, and Matsumoto}}}
\bibcite{yu2016atrous}{{25}{2016}{{Yu and Koltun}}{{}}}
\bibcite{zhang2016colorful}{{26}{2016}{{Zhang et~al.}}{{Zhang, Isola, and Efros}}}
\bibcite{zhou2017places}{{27}{2017}{{Zhou et~al.}}{{Zhou, Lapedriza, Khosla, Oliva, and Torralba}}}
\bibstyle{plainnat}
